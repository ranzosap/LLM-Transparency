# Comprehensive Analysis of Transparency and Accessibility of ChatGPT, DeepSeek, and other SoTA Large Language Models

# Abstract 
Despite growing discourse on open-source artificial intelligence (AI), a critical gap remains in evaluating the transparency and accessibility of state-of-the-art (SoTA) large language models (LLMs). Recent initiatives such as the Open Source Initiative (OSI) definition of open-source software offer a starting point, yet they inadequately address the unique complexities of openness in modern AI systems. Increasing concern around "open-washing" where models claim openness while withholding crucial details undermines reproducibility, fairness, and downstream adaptability. In this study, we present a comprehensive analysis of 121 SoTA LLMs developed between 2019 and 2025, including models such as ChatGPT-4, DeepSeek-R1, LLaMA 2, and Gemini 2.5 Pro. We introduce two standardized metrics: the Composite Transparency Score (CTS), which evaluates openness across seven dimensions (code, weights, data, documentation, license, carbon disclosures, and benchmark reproducibility); and the Training Data Disclosure Index (TDDI), which assesses the specificity and transparency of training dataset reporting. Our results reveal a widening transparency deficit among recent proprietary models, particularly those released in 2025, which often omit key disclosures while reporting high benchmark scores. Conversely, select models such as BLOOM, DeepSeek-R1, and Qwen 3 maintain high transparency standards. We further propose a badge-based labeling framework and advocate for alignment with global responsible AI frameworks, including the EU Ethics Guidelines, OECD Principles, and IEEE Ethically Aligned Design. This study offers the first large-scale CTS/TDDI evaluation and establishes a foundation for promoting reproducible, sustainable, and ethically accountable LLM development in the generative AI era.



# List of References 





# List of Weblinks 

1. https://opensource.org/license/mit

2. https://www.apache.org/licenses/LICENSE-2.0

3. https://creativecommons.org/share-your-work/cclicenses/

4. https://opensource.org/licenses/BSD-3-Clause

5. https://www.gnu.org/licenses/gpl-3.0.en.html

6. https://opensource.org/

7. https://www.oed.com/

8. https://gemini.google/subscriptions/

9. https://cdn.openai.com/gpt-4-5-system-card-2272025.pdf

10. https://deepmind.google/models/gemini/flash-lite/

11. https://deepmind.google/models/gemini/pro/

12. https://openai.com/index/introducing-o3-and-o4-mini/

13. https://openai.com/index/gpt-4-1/

14. https://github.com/QwenLM/Qwen3

15. https://huggingface.co/CohereForAI/c4ai-command-r-plus

16. https://cdn.openai.com/papers/gpt-4.pdf

17. https://x.ai/blog/grok-os

18. https://ai.meta.com/blog/llama-3/

19. https://github.com/openlm-research/open_llama

20. https://huggingface.co/datasets/EleutherAI/proof-pile-2/tree/main/algebraic-stack

21. https://www.gov.uk/government/collections/government-conversion-factors-for-company-reporting

22. https://www.epa.gov/climateleadership/ghg-emission-factors-hub

23. https://carboncredits.com/how-big-is-the-co2-footprint-of-ai-models-chatgpts-emissions/

24. https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm

25. https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/

26. https://keg.cs.tsinghua.edu.cn/jietang/publications/wudao-3.0-meta-en.pdf

27. https://grok.com/

28. https://www-cdn.anthropic.com/fed9cc193a14b84131812372d8d5857f8f304c52/Model_Card_Claude_3_Addendum.pdf

29. https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf

30. https://huggingface.co/Qwen/Qwen2-72B

31. https://huggingface.co/mistralai/Mistral-Large-Instruct-2407

32. https://x.ai/news/grok-3

33. https://crfm.stanford.edu/2023/03/13/alpaca.html

34. https://wizardlm.github.io/WizardLM2/

35. https://platform.openai.com/docs/models/gpt-4o

36. https://openai.com/index/introducing-gpt-4-5/

37. https://www.anthropic.com/news/claude-2

38. https://assets.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf

39. https://platform.openai.com/docs/models

40. https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/MODEL_CARD.md
